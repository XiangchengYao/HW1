{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12c1ea80-77a2-43d6-92b0-05e78864f042",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff39cdc0-f2c8-4974-9bbc-5308dae44cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row_n           0\n",
       "id              1\n",
       "name            0\n",
       "gender          0\n",
       "species         0\n",
       "birthday        0\n",
       "personality     0\n",
       "song           11\n",
       "phrase          0\n",
       "full_id         0\n",
       "url             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b145d6f5-1f9c-4382-b959-8d8123d5123e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "685d9f5a-0430-4f64-9bdd-c51c661000b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(391, 11)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0273360-d825-4718-9fc5-be42035968ab",
   "metadata": {},
   "source": [
    "I found the observations are typically organized as rows in a data set. Each observation represents a single entity, and the data is measured and recorded on that entity.\n",
    "Variables are different things that can be measured and recorded for each entity, so usually correspond to columns in the dataset. Observations therefore consist of values from all the variables in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e62242-323a-4acf-93c0-ca3601e5c4a2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "646a567d-988d-442b-aaad-44acdd59c22c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>391.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>239.902813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>140.702672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>117.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>240.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>363.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>483.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            row_n\n",
       "count  391.000000\n",
       "mean   239.902813\n",
       "std    140.702672\n",
       "min      2.000000\n",
       "25%    117.500000\n",
       "50%    240.000000\n",
       "75%    363.500000\n",
       "max    483.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68c4cc13-9256-41a0-bd0a-194d309c683e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name\n",
       "Admiral    1\n",
       "Muffy      1\n",
       "Paula      1\n",
       "Patty      1\n",
       "Pate       1\n",
       "          ..\n",
       "Elvis      1\n",
       "Eloise     1\n",
       "Elmer      1\n",
       "Ellie      1\n",
       "Zucker     1\n",
       "Name: count, Length: 391, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6306250-8ea7-47dd-916f-de184cef18ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "species\n",
       "cat          23\n",
       "rabbit       20\n",
       "frog         18\n",
       "squirrel     18\n",
       "duck         17\n",
       "dog          16\n",
       "cub          16\n",
       "pig          15\n",
       "bear         15\n",
       "mouse        15\n",
       "horse        15\n",
       "bird         13\n",
       "penguin      13\n",
       "sheep        13\n",
       "elephant     11\n",
       "wolf         11\n",
       "ostrich      10\n",
       "deer         10\n",
       "eagle         9\n",
       "gorilla       9\n",
       "chicken       9\n",
       "koala         9\n",
       "goat          8\n",
       "hamster       8\n",
       "kangaroo      8\n",
       "monkey        8\n",
       "anteater      7\n",
       "hippo         7\n",
       "tiger         7\n",
       "alligator     7\n",
       "lion          7\n",
       "bull          6\n",
       "rhino         6\n",
       "cow           4\n",
       "octopus       3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['species'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "032edb16-3f60-4fe1-aa4c-1151834880eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "birthday\n",
       "1-27     2\n",
       "12-5     2\n",
       "7-31     2\n",
       "3-26     2\n",
       "8-3      2\n",
       "        ..\n",
       "4-3      1\n",
       "10-26    1\n",
       "7-23     1\n",
       "12-8     1\n",
       "3-8      1\n",
       "Name: count, Length: 361, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['birthday'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0b7c10-241f-48b7-a8dd-c2095961a9a9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d72b450-cb39-4f5e-9a06-95262e88907b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7066e4cd-e639-448a-8b58-17d47d567e6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 15)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7061ae9-d34b-4810-b4c3-de0fba70ec37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         survived      pclass         age       sibsp       parch        fare\n",
       "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
       "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
       "std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
       "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
       "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
       "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
       "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
       "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096af912-21c6-4658-94ba-0dba288a40c9",
   "metadata": {},
   "source": [
    "(a)\n",
    "df.shape returns a tuple of the number of rows and columns in the dataset, including numeric and non-numeric columns.\n",
    "df.describe() analyzes and summarizes only numeric columns. it will be less than the number of columns returned by df.shape."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09407e4a-828d-429b-80d7-6fc1f8d93170",
   "metadata": {},
   "source": [
    "(b)\n",
    "df.shape does not provide any information about missing values. It only returns the overall dimension of the dataset.\r\n",
    "The “count” column reports the number of non-missing values for each numeric column in the output of df.describe()."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdfd02c-16b0-4999-836a-4bd5ff72c546",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677b1620-54cc-46a2-a16d-c2d13158612c",
   "metadata": {},
   "source": [
    "df.shape doesn't need parentheses because it only accesses information that the object already has.\n",
    "df.describe() needs parentheses because it is calling a function that may take input parameters and return a result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b55f3b1-3d95-48c0-9fda-d35d8ff8b201",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 6."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff971846-caa9-45e1-ad70-88a4a29b178f",
   "metadata": {},
   "source": [
    "Count: the number of non-missing values. Mathematically, this is usually denoted by n. This is different from the number of rows returned by df.shape, which counts all rows, including those columns with missing values.\n",
    "\n",
    "Mean: the average of the values, calculated by adding all the values and dividing by the count of non-missing values.\n",
    "\n",
    "Standard deviation (std): A measure of how dispersed the data are around the mean. It is a measure of the average distance between a data point and its mean.\n",
    "\n",
    "Minimum (min): The smallest value of the variable in the data set.\n",
    "\n",
    "25%: first quartile (Q1). 25% of the data is below this value.\n",
    "\n",
    "50%: the second quartile (Q2), also known as the median. 50% of the data falls below this value.\n",
    "\n",
    "75%: the third quartile (Q3). 75% of the data fall below this value.\n",
    "\n",
    "Maximum (max): The maximum value of the variable in the data set.data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c108127-2045-45be-b7cf-b24cafbe1756",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 7."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac30778-e8d7-4980-8986-f5408911224c",
   "metadata": {},
   "source": [
    "1.\n",
    "It is often preferable to use df.dropna() when missing values are randomly distributed in the dataset and deleting rows containing missing values does not result in significant loss of information.\r",
    "2.\n",
    "When there are a large number of missing values in a column, or when the column is not relevant to your analysis, it is often preferable to use del df['col']\n",
    "3.\n",
    "When both del df['col'] and df.dropna() are used, del df['col'] is applied first because deleting whole columns reduces the amount of data and increases efficiency.y.4. s missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e899d7e-c438-41e2-b14f-5aa2d523044d",
   "metadata": {},
   "source": [
    "4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b12da976-6ff8-43d1-95b4-b2b3c7965c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before data preprocessing: (391, 11)\n",
      "Count of missing values before data preprocessing: \n",
      " row_n           0\n",
      "id              1\n",
      "name            0\n",
      "gender          0\n",
      "species         0\n",
      "birthday        0\n",
      "personality     0\n",
      "song           11\n",
      "phrase          0\n",
      "full_id         0\n",
      "url             0\n",
      "dtype: int64\n",
      "Shape after data preprocessing: (391, 10)\n",
      "Count of missing values after data preprocessing: \n",
      " id              1\n",
      "name            0\n",
      "gender          0\n",
      "species         0\n",
      "birthday        0\n",
      "personality     0\n",
      "song           11\n",
      "phrase          0\n",
      "full_id         0\n",
      "url             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\")\n",
    "print(\"Shape before data preprocessing:\", df.shape)\n",
    "print(\"Count of missing values before data preprocessing: \\n\", df.isna().sum())\n",
    "del df['row_n']\n",
    "print(\"Shape after data preprocessing:\", df.shape)\n",
    "print(\"Count of missing values after data preprocessing: \\n\", df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e422e64-8d81-44d7-83b9-8378068dbcda",
   "metadata": {},
   "source": [
    "Rationale\n",
    "Our approach is to first examine which columns contain missing values and then evaluate whether they are needed. row_n column can be safely removed as it does not appear to be a critical variable needed for the analysis. After removing the row_n column, the dataset no longer contains missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205dedde-8f6f-4f61-9e4a-0e4a685d67fd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 8."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79eef15-a773-44e5-8cf3-c9c3316d9d32",
   "metadata": {},
   "source": [
    "1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8305c5b7-b89f-4244-a1d1-29e505fc9451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare',\n",
       "       'embarked', 'class', 'who', 'adult_male', 'deck', 'embark_town',\n",
       "       'alive', 'alone'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "317b4007-7440-4301-b3b0-932c1f547d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>survived</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>549.0</td>\n",
       "      <td>22.117887</td>\n",
       "      <td>31.388207</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>10.5</td>\n",
       "      <td>26.0</td>\n",
       "      <td>263.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>342.0</td>\n",
       "      <td>48.395408</td>\n",
       "      <td>66.596998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.4750</td>\n",
       "      <td>26.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>512.3292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count       mean        std  min      25%   50%   75%       max\n",
       "survived                                                                 \n",
       "0         549.0  22.117887  31.388207  0.0   7.8542  10.5  26.0  263.0000\n",
       "1         342.0  48.395408  66.596998  0.0  12.4750  26.0  57.0  512.3292"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\" \n",
    "df = pd.read_csv(url)\n",
    "\n",
    "df.groupby(\"survived\")[\"fare\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a1fbe0-10ce-4a36-8d0a-0deffb5fa142",
   "metadata": {},
   "source": [
    "2.\n",
    "This is because they compute different types of counts. the counts in df.describe() reflect the amount of missing data for each variable, while the counts in df.groupby(“col1”)[“col2”]. The counts in describe() reflect the sample size of the “col2” variable within each group."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b395f4-10be-4aa7-a513-48542aa9476d",
   "metadata": {},
   "source": [
    "3.\n",
    "ChatBot better: A, C, E, F, G\n",
    "\n",
    "Google better: B, D\n",
    "\n",
    "A: NameError: name 'pd' is not defined\n",
    "\n",
    "B: FileNotFoundError: [Errno 2] No such file or directory: 'titanics.csv' (Assuming the file does not exist)\n",
    "\n",
    "C: NameError: name 'DF' is not defined\n",
    "\n",
    "D: This depends on where you are missing the parentheses, but may result in a SyntaxError or other error.\n",
    "\n",
    "E: AttributeError: 'DataFrame' object has no attribute 'group_by'\n",
    "\n",
    "F: KeyError: 'Sex'\n",
    "\n",
    "G: NameError: name 'sex' is not defined (if you used titanic_df.groupby(sex)[“age”].describe())\n",
    "NameError: name 'age' is not defined (if you are using titanic_df.groupby(“sex”)[age].describe()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e062758-29c5-412e-a5f6-e020a6a3b49c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 9."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d268fbb4-19bf-4b3a-884b-1b24b64aa681",
   "metadata": {},
   "source": [
    "Yes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36b13f4-2c04-42c4-a27a-1d5883a7937f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# STA130 Custom NBLM Chatbot conversation summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190df4f7-fc68-496b-842d-d0ae58f77d54",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "\n",
    "Our conversation centered around understanding data summary statistics using the `df.describe()` method and exploring how to effectively use `df.dropna()` and `del df['col']` to handle missing data in a dataset.\r\n",
    "\r\n",
    "First, we **define the summary statistics** provided by the `df.describe()` method, including counts, mean, standard deviation, minimum, maximum, and quartiles (25%, 50%, and 75%). We also discussed that the `df.describe()` method **applies only to numeric variables** and automatically ignores missing values when calculating statistics.\r\n",
    "\r\n",
    "Next, we **compared the `df.dropna()` and `del df['col']` methods **for handling missing data. We explore the scenarios in which each method is applicable and analyze why `del df['col']` is often recommended to be applied first when using a combination of the two methods.\r\n",
    "\r\n",
    "Using the example of the Friends of Animals dataset,** we demonstrated how to use `del df['col']` to remove columns that contain a large number of missing values** (`row_n` columns). We also explained the rationale for this approach and emphasized the importance of checking for missing values and backing up the original data before deleting it.\r\n",
    "\r\n",
    "Finally, we **summarized how to effectively use `df.dropna()` and `del df['col']` to deal with missing data** and emphasized the importance of choosing the most appropriate method for a specific situation. \r\n",
    "\r\n",
    "**In summary, our discussion covered understanding data summary statistics, different approaches to dealing with missing data, and how to choose the most effective approach based on data characteristics and analysi\n",
    "\n",
    "\r\n",
    "The focus of our discussion is to compare **ChatBot** with **Google Search** to determine which approach is more effective at fixing various errors that are intentionally introduced in Python code.  \r\n",
    "\r\n",
    "You explored three specific types of errors:\r\n",
    "\r\n",
    "1. **Using column names in `groupby` and column selection that don't exist in the data:** [previous conversation]\r\n",
    "2. **Forgetting to add quotes to a column name in `groupby` and column selection:** [previous conversation]\r\n",
    "3. **Forgot to import pandas:** [previous conversation]\r\n",
    "\r\n",
    "For each error type, you asked about my experience solving the problem using **ChatBot** and **Google Search**, and asked me to evaluate which method was more effective. \r\n",
    "\r\n",
    "### Conclusion\r\n",
    "\r\n",
    "Overall, you found that both **ChatBot** and **Google Search** can help solve these coding errors. However, **which method is more effective depends on the circumstances, including the nature of the error, your previous conversation history, and your familiarity with **ChatBot** and **Google Search**. ** [previous conversation]\r\n",
    "\r\n",
    "### Specific analysis of the three error types\r\n",
    "\r\n",
    "* **Using column names that don't exist in the data:** \r\n",
    "\r\n",
    "    ** If your **ChatBot** session contains code that you previously loaded the data and displayed the column names, it may recognize this error and suggest that you use the correct column names.  [previous conversation]\r\n",
    "    * Searching Google for relevant error messages may also display resources that explain the error and provide a solution.  [previous conversation]\r\n",
    "* **Forgot to add quotes to column names in `groupby` and column selection:** \r\n",
    "\r\n",
    "    * * Similar to the previous error, the effect of **ChatBot** depends on your previous conversation history. If it has access to your code history and understands your intent, it may provide more immediate help.  [previous conversation]\r\n",
    "    * Google Search can provide a more generalized solution because it has access to a wider range of code examples and documentation.  [previous conversation]\r\n",
    "* **Forgot to import pandas: ** \r\n",
    "\r\n",
    "    * **ChatBot** and Google Search can both help with this.  [previous conversation] **ChatBot** and Google Search can help with this.\r\n",
    "    * **ChatBot** may be able to help more directly if it has access to your code history and can see that you have imported pandas before.  [previous conversation] * Google Search offers a more generalized approach.\r\n",
    "    * Google Search provides a more generalized solution because it has access to a wider range of code examples and documentation.  [previous conversation]\r\n",
    "\r\n",
    "### Relevant information from sources\r\n",
    "\r\n",
    "Although the sources do not directly address these specific coding errors, they do provide some relevant background information. For example, the sources mention the use of `groupby` and the importance of importing libraries such as pandas.  \r\n",
    "\r\n",
    "### Final thoughts\r\n",
    "\r\n",
    "Comparing **ChatBot** to **Google Search** for resolving coding errors is an interesting and valuable exercise. By understanding the strengths and weaknesses of each approach, you can make an informed decision about which tool is best suited for your particular needs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
